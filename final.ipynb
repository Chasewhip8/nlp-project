{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e556c44f-d335-46dc-80dc-72334700ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chase/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "2024-04-26 03:17:04.547935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 03:17:04.547970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 03:17:04.549062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 03:17:04.555295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 03:17:05.345832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc6763",
   "metadata": {},
   "source": [
    "# Static Config\n",
    "Values that may have code related assumptions, changing these may require a code change in any of the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0efe51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "NUM_OUT = 3\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "# MODEL_LAYER = BertModel.from_pretrained(MODEL)\n",
    "MODEL_LAYER = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL, \n",
    "    num_labels=NUM_OUT,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd02cfa",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "Below are utilities used across the codebase, in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ba4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_window(seconds):\n",
    "    return np.floor(seconds / TIME_WINDOW) * TIME_WINDOW\n",
    "\n",
    "def convert_raw_messages(df, start_time, end_time):\n",
    "    # Drop columns not in ['Date', 'Content']\n",
    "    df.drop(columns=[col for col in df.columns if col not in ['Date', 'Content']], inplace=True)\n",
    "\n",
    "    # Convert 'Date' from UTC to seconds from epoch\n",
    "    df['Date'] = pd.to_datetime(df['Date']).astype(int) / 1e9\n",
    "\n",
    "    # Rename the columns to 'time' and 'content'\n",
    "    df.rename(columns={'Date': 'time', 'Content': 'content'}, inplace=True)\n",
    "\n",
    "    # Filter the DataFrame to only include rows within the specified time range\n",
    "    df = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "    \n",
    "    # Filter out small messages\n",
    "    df = df[df['content'].str.len() >= MIN_MESSSAGE_LEN]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cae5fe",
   "metadata": {},
   "source": [
    "### Signal Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338fdab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vwap_signals(df, sec_window):\n",
    "    # Set the time column as the index and convert it to datetime\n",
    "    df.set_index(pd.to_datetime(df['time'], unit='s'), inplace=True)\n",
    "    \n",
    "    # Calculate VWAP using resampling\n",
    "    vwap_values = df.resample(f'{sec_window}s').apply(\n",
    "        lambda x: np.dot(x['price'], x['volume']) / x['volume'].sum() if not x.empty else np.nan\n",
    "    )\n",
    "    \n",
    "    # Use forward fill to replace NaN values with the last known value\n",
    "    vwap_values.fillna(method='ffill', inplace=True)\n",
    "    # If the entire series starts with NaN, replace remaining NaNs with zero\n",
    "    vwap_values.fillna(0, inplace=True)\n",
    "    \n",
    "    # Calculate the changes in VWAP\n",
    "    vwap_changes = vwap_values.diff().fillna(0)\n",
    "    # Calculate the percentage changes relative to the previous VWAP value\n",
    "    percentage_changes = np.where(vwap_values.shift(1) != 0, vwap_changes / vwap_values.shift(1), 0)\n",
    "    \n",
    "    # Replace infinite and NaN values with 0 for signal calculation\n",
    "    percentage_changes = np.nan_to_num(percentage_changes, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Map the percentage changes in VWAP to signals with DELTA_BUFFER consideration\n",
    "    def signal_mapping(pct_change):\n",
    "        if abs(pct_change) <= DELTA_BUFFER:\n",
    "            return 1\n",
    "        elif pct_change > 0:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    signals = pd.Series(percentage_changes, index=vwap_values.index).apply(signal_mapping)\n",
    "    \n",
    "    # Convert index to seconds from epoch\n",
    "    signals.index = (signals.index - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "    \n",
    "    # Determine the start and end timestamp if signals are not empty\n",
    "    start_timestamp = signals.index[0] if not signals.empty else None\n",
    "    end_timestamp = signals.index[-1] if not signals.empty else None\n",
    "    \n",
    "    return signals, start_timestamp, end_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2744f47",
   "metadata": {},
   "source": [
    "### Message Process Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c65d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noop(df):\n",
    "    return df\n",
    "\n",
    "def contains_keywords(df):\n",
    "    filterWords = [\"sol\", \"solana\", \"pump\", \"dump\", \"pumping\", \"dumping\", \"bullish\", \"bearish\"]\n",
    "    \n",
    "    def filterFn(text):\n",
    "        text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        return any(word in text for word in filterWords)\n",
    "    \n",
    "    return df[df['content'].apply(filterFn)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef318d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7042289",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 2e-05\n",
    "\n",
    "MIN_MESSSAGE_LEN = 16\n",
    "MAX_MESSSAGE_LEN = 64\n",
    "TIME_WINDOW = 60 * 30 # 60 * 2\n",
    "DELTA_BUFFER = 0.001\n",
    "\n",
    "TRADE_DATA_PATH = \"trade_data\"\n",
    "MESSAGE_DATA_PATH = \"discord_data\"\n",
    "\n",
    "SIGNAL_PROCESS_FN = vwap_signals\n",
    "MESSAGE_PROCESS_FN = noop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b8efc",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b8593",
   "metadata": {},
   "source": [
    "### Load all data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca29cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data_raw_files = []\n",
    "for filename in os.listdir(TRADE_DATA_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        trade_data_raw_files.append(os.path.join(TRADE_DATA_PATH, filename));\n",
    "        \n",
    "message_data_raw_files = []\n",
    "for filename in os.listdir(MESSAGE_DATA_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        message_data_raw_files.append(os.path.join(MESSAGE_DATA_PATH, filename));\n",
    "\n",
    "(len(trade_data_raw_files), len(message_data_raw_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7800a679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "1623943800    1\n",
       "1623945600    0\n",
       "1623947400    0\n",
       "1623949200    0\n",
       "1623951000    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_trade_data(filename):\n",
    "    data = pd.read_csv(filename, names=[\"time\", \"price\", \"volume\"])\n",
    "    return vwap_signals(data, TIME_WINDOW)\n",
    "\n",
    "trade_data, start_timestamp, end_timestamp = load_trade_data(\"trade_data/SOLUSD.csv\")\n",
    "\n",
    "trade_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a366be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.624053e+09</td>\n",
       "      <td>Anyone know good, safe farms on Polygon? I am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.624054e+09</td>\n",
       "      <td>If you're looking for 'safe farm' in particula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.624054e+09</td>\n",
       "      <td>+ Sushi's and Quick's not bad either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624056e+09</td>\n",
       "      <td>dope yeah I hadn't looked at curve (idk why) b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.624056e+09</td>\n",
       "      <td>This is my past 2 days in trading SMH .... hop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time                                            content\n",
       "0  1.624053e+09  Anyone know good, safe farms on Polygon? I am ...\n",
       "1  1.624054e+09  If you're looking for 'safe farm' in particula...\n",
       "2  1.624054e+09               + Sushi's and Quick's not bad either\n",
       "3  1.624056e+09  dope yeah I hadn't looked at curve (idk why) b...\n",
       "4  1.624056e+09  This is my past 2 days in trading SMH .... hop..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_messages(filename, start_time, end_time):\n",
    "    data = pd.read_csv(filename)\n",
    "    converted = convert_raw_messages(data, start_time, end_time)\n",
    "    return MESSAGE_PROCESS_FN(converted)\n",
    "\n",
    "message_data = None\n",
    "\n",
    "for messages_file in message_data_raw_files:\n",
    "    data = load_messages(messages_file, start_timestamp, end_timestamp)\n",
    "    if message_data is None:\n",
    "        message_data = data\n",
    "    else:\n",
    "        message_data = pd.concat([message_data, data], ignore_index=True)\n",
    "        \n",
    "message_data.dropna(subset=['content'], inplace=True)\n",
    "message_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "message_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae28a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradeMessageDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.targets = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        (time, text) = self.text.loc[index]\n",
    "        \n",
    "        # BERT Encoder\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_MESSSAGE_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        # Target\n",
    "        target = self.targets[round_to_nearest_window(time)]\n",
    "        target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': target_tensor, \n",
    "            'raw_targets': target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3fe85e5-12ad-46cc-9396-49a617a83c41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Entries: 101896\n",
      "Test Data Entries: 43670\n"
     ]
    }
   ],
   "source": [
    "training_data_df, test_data_df = train_test_split(message_data, test_size=0.3, random_state=20)\n",
    "\n",
    "training_data_df.reset_index(inplace=True, drop=True)\n",
    "training_data = TradeMessageDataLoader(training_data_df, trade_data, TOKENIZER)\n",
    "\n",
    "test_data_df.reset_index(inplace=True, drop=True)\n",
    "test_data = TradeMessageDataLoader(test_data_df, trade_data, TOKENIZER)\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }    \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, **train_params)\n",
    "testing_loader = torch.utils.data.DataLoader(test_data, **test_params)\n",
    "\n",
    "print(f'Training Data Entries: {len(training_data)}')\n",
    "print(f'Test Data Entries: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302dcae",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1965a9c-fe37-457c-a336-74f27e237e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BERTClass(torch.nn.Module):\n",
    "#     def __init__(self, NUM_OUT):\n",
    "#         super(BERTClass, self).__init__()\n",
    "                   \n",
    "#         self.l1 = BertModel.from_pretrained(MODEL)\n",
    "# #       self.l1 = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "# #       self.pre_classifier = torch.nn.Linear(768, 256)\n",
    "#         self.classifier = torch.nn.Linear(768, NUM_OUT)\n",
    "# #       self.dropout = torch.nn.Dropout(0.5)\n",
    "#         self.softmax = torch.nn.Softmtput)\n",
    "#         return output\n",
    "\n",
    "# class CustomModel(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.base = MODEL_LAYER\n",
    "#         self.n1 = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.3)\n",
    "#         self.classifier = torch.nn.Linear(768, NUM_OUT)\n",
    "        \n",
    "#         # Inference Only\n",
    "#         self.softmax = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "#         outputs = self.base(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "#         pooled_output = outputs.pooler_output\n",
    "#         n1 = self.n1(pooled_output)\n",
    "#         pooled_output = self.dropout(n1)\n",
    "#         logits = self.classifier(pooled_output)\n",
    "#         return logits\n",
    "    \n",
    "#     # Apply softmax to final output\n",
    "#     def predict(self, ids, mask, token_type_ids):\n",
    "#         logits = self.forward(ids, mask, token_type_ids)\n",
    "#         probabilities = self.softmax(logits)\n",
    "#         return probabilities\n",
    "\n",
    "# model = CustomModel()\n",
    "model = MODEL_LAYER\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW (model.parameters(),\n",
    "                  lr = LEARNING_RATE,\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "total_steps = len(training_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f07c9df-fbe2-487c-ac3c-3c95daf6a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        optimizer.zero_grad();\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids, labels=targets)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)    \n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return loss\n",
    "    \n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            logits = outputs.logits.detach().cpu().numpy()\n",
    "            outputs = np.argmax(logits, axis=1).flatten()\n",
    "            targets = data['raw_targets']\n",
    "            \n",
    "            fin_outputs.extend(outputs)\n",
    "            fin_targets.extend(targets)\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424d09d-3373-46c1-b039-9a7408a3bf37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▊                                                                                                             | 107/1593 [00:43<10:13,  2.42it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, training_loader, optimizer)\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "    \n",
    "    outputs, targets = validation(model, testing_loader)\n",
    "    print('accuracy on test set {}'.format(accuracy_score(outputs, targets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e01c39",
   "metadata": {},
   "source": [
    "### Save and load model (only for inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987846c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"model_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ad965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"model_v1.pt\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656d50f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list = [t.item() for t in targets]\n",
    "targets_counter = Counter(targets_list)\n",
    "targets_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b319b60",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe53003",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets, outputs)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm) # , display_labels=clf.classes_\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2939e1",
   "metadata": {},
   "source": [
    "### Label Accuracy Rate\n",
    "Probability the model guesses the label correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_rate(label):\n",
    "    num_wrong = 0\n",
    "    count = 0\n",
    "    for (output, target) in zip(outputs, targets_list):\n",
    "        if output != label:\n",
    "            continue\n",
    "        count += 1\n",
    "        if output != target:\n",
    "            num_wrong += 1\n",
    "    return 1.0 - (num_wrong / count) if count > 0 else \"N/A\" \n",
    "\n",
    "for label in range(NUM_OUT):\n",
    "    print(f\"Label Accuracy Rate for {label}: {calculate_accuracy_rate(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c5237",
   "metadata": {},
   "source": [
    "### Label Accuracy Probability\n",
    "Given that we have a label and it is correct, what is the probability the model guesses it correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error_rate_per_label(label):\n",
    "    num_wrong = 0\n",
    "    count = 0\n",
    "    for (output, target) in zip(outputs, targets_list):\n",
    "        if target != label:\n",
    "            continue\n",
    "        count += 1\n",
    "        if output != target:\n",
    "            num_wrong += 1\n",
    "    return 1 - (num_wrong / count) if count > 0 else \"N/A\" \n",
    "\n",
    "for label in range(NUM_OUT):\n",
    "    print(f\"Label Accuracy Probability for {label}: {calculate_error_rate_per_label(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25c720",
   "metadata": {},
   "source": [
    "### Most Common Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a673149",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 0\n",
    "for label in range(NUM_OUT):\n",
    "    val = targets_counter[label]\n",
    "    if val > tmp:\n",
    "        tmp = val\n",
    "\n",
    "print(f\"Most Common Baseline: {tmp / len(targets_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e22276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
