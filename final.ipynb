{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e556c44f-d335-46dc-80dc-72334700ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chase/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc6763",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dab0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Config\n",
    "MODEL = \"bert-base-uncased\"\n",
    "MAX_LEN = 128 # This should be changed to max token length iirc 512\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "NUM_OUT = 3\n",
    "LEARNING_RATE = 2e-05\n",
    "\n",
    "# Data Config\n",
    "TIME_WINDOW = 60 * 5\n",
    "TRADE_DATA_PATH = \"trade_data\"\n",
    "MESSAGE_DATA_PATH = \"discord_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b8efc",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca29cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 234)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trade data for every pair in the config list\n",
    "trade_data_raw_files = []\n",
    "for filename in os.listdir(TRADE_DATA_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        trade_data_raw_files.append(os.path.join(TRADE_DATA_PATH, filename));\n",
    "        \n",
    "message_data_raw_files = []\n",
    "for filename in os.listdir(MESSAGE_DATA_PATH):\n",
    "    if filename.endswith('.csv'):\n",
    "        message_data_raw_files.append(os.path.join(MESSAGE_DATA_PATH, filename));\n",
    "        \n",
    "(len(trade_data_raw_files), len(message_data_raw_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ee1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest_window(seconds):\n",
    "    return np.floor(seconds / TIME_WINDOW) * TIME_WINDOW\n",
    "\n",
    "def vwap_signals(df, sec_window):\n",
    "    # Set the time column as the index, convert it during the set_index to avoid an extra step\n",
    "    df.set_index(pd.to_datetime(df['time'], unit='s'), inplace=True)\n",
    "    \n",
    "    # Use a more optimized way of calculating VWAP directly in the resampling\n",
    "    vwap_values = df.resample(f'{sec_window}s').apply(\n",
    "        lambda x: np.dot(x['price'], x['volume']) / x['volume'].sum() if not x.empty else np.nan\n",
    "    )\n",
    "    \n",
    "    # Instead of dropping NaN, fill them with 0\n",
    "    vwap_values.fillna(0, inplace=True)\n",
    "    \n",
    "    # Calculate the changes in VWAP and map to signals efficiently\n",
    "    vwap_changes = np.sign(vwap_values.diff()).fillna(0).astype(int)\n",
    "    signals = vwap_changes.map({-1: 0, 0: 1, 1: 2})\n",
    "    \n",
    "    # Convert index to seconds from epoch\n",
    "    signals.index = (signals.index - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "    \n",
    "    # Determine the start and end timestamp if signals are not empty\n",
    "    if not signals.empty:\n",
    "        start_timestamp = signals.index[0]\n",
    "        end_timestamp = signals.index[-1]\n",
    "    else:\n",
    "        start_timestamp = None\n",
    "        end_timestamp = None\n",
    "    \n",
    "    return signals, start_timestamp, end_timestamp\n",
    "    \n",
    "def load_trade_data(filename):\n",
    "    data = pd.read_csv(filename, names=[\"time\", \"price\", \"volume\"])\n",
    "    return vwap_signals(data, TIME_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6fbca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw_messages(df, start_time, end_time):\n",
    "    # Drop columns not in ['Date', 'Content']\n",
    "    df.drop(columns=[col for col in df.columns if col not in ['Date', 'Content']], inplace=True)\n",
    "\n",
    "    # Convert 'Date' from UTC to seconds from epoch\n",
    "    df['Date'] = pd.to_datetime(df['Date']).astype(int) / 1e9\n",
    "\n",
    "    # Rename the columns to 'time' and 'content'\n",
    "    df.rename(columns={'Date': 'time', 'Content': 'content'}, inplace=True)\n",
    "\n",
    "    # Filter the DataFrame to only include rows within the specified time range\n",
    "    df = df[(df['time'] >= start_time) & (df['time'] <= end_time)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_messages(filename, start_time, end_time):\n",
    "    data = pd.read_csv(filename)\n",
    "    return convert_raw_messages(data, start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25df41",
   "metadata": {},
   "source": [
    "#### Load the actual trade dataset and merge all the messages in each time group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a30646",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data, start_timestamp, end_timestamp = load_trade_data(\"trade_data/SOLUSD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591fbda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46503/3381409967.py:17: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(filename)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.700667e+09</td>\n",
       "      <td>This server's objective is to coordinate Solan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.675388e+09</td>\n",
       "      <td>Add the ✅ reaction to continue.\\n\\nAdditionall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.678841e+09</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.678843e+09</td>\n",
       "      <td>:hi:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.678844e+09</td>\n",
       "      <td>Welcome leaf people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.684080e+09</td>\n",
       "      <td>oops, it was keccak256 not ed25519 that solang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.684080e+09</td>\n",
       "      <td>haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.684080e+09</td>\n",
       "      <td>who do you think would be best to additionally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.684080e+09</td>\n",
       "      <td>In terms of desired usage, I'd just like to ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.684081e+09</td>\n",
       "      <td>nice that does seem to fit the native program ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time                                            content\n",
       "0     1.700667e+09  This server's objective is to coordinate Solan...\n",
       "1     1.675388e+09  Add the ✅ reaction to continue.\\n\\nAdditionall...\n",
       "2     1.678841e+09                                                 Hi\n",
       "3     1.678843e+09                                               :hi:\n",
       "4     1.678844e+09                               Welcome leaf people!\n",
       "...            ...                                                ...\n",
       "9995  1.684080e+09  oops, it was keccak256 not ed25519 that solang...\n",
       "9996  1.684080e+09                                               haha\n",
       "9997  1.684080e+09  who do you think would be best to additionally...\n",
       "9998  1.684080e+09  In terms of desired usage, I'd just like to ai...\n",
       "9999  1.684081e+09  nice that does seem to fit the native program ...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_data = None\n",
    "\n",
    "for messages_file in message_data_raw_files:\n",
    "    data = load_messages(messages_file, start_timestamp, end_timestamp)\n",
    "    if message_data is None:\n",
    "        message_data = data\n",
    "    else:\n",
    "        message_data = pd.concat([message_data, data], ignore_index=True)\n",
    "message_data.dropna(subset=['content'], inplace=True)\n",
    "message_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "message_data = message_data.iloc[:10000] # ONLY FIRST 10000 FOR TESTING\n",
    "\n",
    "message_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7c56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradeMessageDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, labels, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.targets = labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        (time, text) = self.text.loc[index]\n",
    "        \n",
    "        # BERT Encoder\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        # Target\n",
    "        target = self.targets[round_to_nearest_window(time)]\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(target, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302dcae",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0c2438-fa34-4301-92e9-5f5bc9f0529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([\"it's going up\", \"you ruined my day\",\"this is a good investment\", \"wow, numbers go brrrrrrr\", \"lol\",\"going up\",\"going down\",\"going flat\",\"it's a bear\",\"it's a bull\",\"butterflies are cool\",\"git good\",\"why do I care\",\"get rekt nerd\", \"you're so bad at this\",\"stocks tanking\",\"I'm not too confident this'll go up\",\"big numbers\", \"it'll go up\", \"outlook good\"])\n",
    "# y = np.array([0,2,0,0,1,0,2,1,2,0,1,1,1,1,1,2,2,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1965a9c-fe37-457c-a336-74f27e237e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, NUM_OUT):\n",
    "        super(BERTClass, self).__init__()\n",
    "                   \n",
    "        self.l1 = BertModel.from_pretrained(MODEL)\n",
    "#       self.l1 = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "#       self.pre_classifier = torch.nn.Linear(768, 256)\n",
    "        self.classifier = torch.nn.Linear(768, NUM_OUT)\n",
    "#       self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "#       pooler = self.pre_classifier(pooler)\n",
    "#       pooler = torch.nn.Tanh()(pooler)\n",
    "#       pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f07c9df-fbe2-487c-ac3c-3c95daf6a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "def train(model, training_loader, optimizer):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "    \n",
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testing_loader):\n",
    "            targets = data['targets']\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            outputs = torch.sigmoid(outputs).cpu().detach()\n",
    "            fin_outputs.extend(outputs)\n",
    "            fin_targets.extend(targets)\n",
    "    return torch.stack(fin_outputs), torch.stack(fin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd19da69-2afa-4534-9a3f-a91b3dc45701",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3fe85e5-12ad-46cc-9396-49a617a83c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = TradeMessageDataLoader(message_data, trade_data, tokenizer, MAX_LEN)\n",
    "test_data = TradeMessageDataLoader(message_data, trade_data, tokenizer, MAX_LEN)\n",
    "\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }    \n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_data, **train_params)\n",
    "testing_loader = torch.utils.data.DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424d09d-3373-46c1-b039-9a7408a3bf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [02:08<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.9440982937812805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [00:48<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set 0.5899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [02:11<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  1.0057735443115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [00:50<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [02:12<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.9532208442687988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [00:49<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set 0.8057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [02:09<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.7888864278793335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [00:48<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [02:09<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.5955169796943665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 313/313 [00:48<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set 0.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▋                          | 8/313 [00:02<02:02,  2.48it/s]"
     ]
    }
   ],
   "source": [
    "model = BERTClass(NUM_OUT)\n",
    "model.to(device)    \n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, training_loader, optimizer)\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')  \n",
    "    guess, targs = validation(model, testing_loader)\n",
    "    guesses = torch.max(guess, dim=1)\n",
    "    targets = targs\n",
    "    print('accuracy on test set {}'.format(accuracy_score(guesses.indices, targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53ba5b-a013-4b3f-9f54-7117f86bf1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8aa10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
